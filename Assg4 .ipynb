{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "XsJLpFAUt5ep"
      },
      "outputs": [],
      "source": [
        "#importing libraries \n",
        "import pandas as pd \n",
        "import numpy as np\n",
        "import random\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Creating Dataset**"
      ],
      "metadata": {
        "id": "tqVdq2KIWw0t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Set the random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# Defining the number of samples in the dataset\n",
        "num_samples = 5000\n",
        "\n",
        "# Defining the maximum length of each sequence\n",
        "max_seq_len = 50\n",
        "\n",
        "# Generate the dataset\n",
        "X = []\n",
        "Y = []\n",
        "for i in range(num_samples):\n",
        "    # Generate a random sequence of variable length\n",
        "    # seq_len = np.random.randint(1, max_seq_len+1)\n",
        "    seq_len = 10\n",
        "    x1 = np.random.rand(seq_len, 1) #all numbers between 0 and 1\n",
        "   \n",
        "    # Generate a random binary label\n",
        "    x2 = np.random.randint(1, size=seq_len) #all zeroes\n",
        "    \n",
        "    indices = random.sample(range(seq_len), k=2) #choosing two random indices of the sequence whose 2nd dim will be replaced by 1\n",
        "    x2[indices[0]] = 1\n",
        "    x2[indices[1]] = 1\n",
        "\n",
        "    x2=x2.reshape(seq_len,1)\n",
        "    x = np.concatenate((x1, x2), axis=1) #array of shape: (seq_len,2)\n",
        "    # print(x1.shape)\n",
        "    # print(x2.shape)\n",
        "    # print(x.shape)\n",
        "    X.append(x)\n",
        "\n",
        "\n",
        "for i in range(num_samples): #X.shape[0]\n",
        "  sum = 0\n",
        "  for j in range(X[i].shape[0]):\n",
        "    if X[i][j][1] == 1:\n",
        "      sum=sum+X[i][j][0]\n",
        "  Y.append(sum)\n",
        "\n",
        "# Convert the dataset to numpy arrays\n",
        "X = np.array(X) #datapoints\n",
        "Y = np.array(Y) #labels\n",
        "Y = Y.reshape(5000,1)\n",
        "  \n",
        "\n"
      ],
      "metadata": {
        "id": "C1ELF6fUB5W2"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X[0][5][0]) #1st dim of 6th sequence of 1st datapoint (out of 5000 datapoints)\n",
        "print(X[0][5][1]) #2nd dim of 6th sequence of 1st datapoint (out of 5000 datapoints)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FhMPpmUgB7EN",
        "outputId": "d0e54771-44e3-40fd-e5c8-1992b7a9018d"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.15599452033620265\n",
            "0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X[0].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j9eTUZBMJ6F4",
        "outputId": "1f8716ec-353f-4bcb-f04f-58e7b9053a84"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(Y[4900])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uld8h2PySXMG",
        "outputId": "b972c11d-141c-4f75-974e-e049cc785e50"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1.14940028]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X.shape) # 5000xnx2\n",
        "print(Y.shape) #5000x1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YiR2Y3bkWwgE",
        "outputId": "faf1cb2d-4c15-4dbe-b6fc-66b1dd92edbb"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5000, 10, 2)\n",
            "(5000, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dividing the dataset into a train set and a test set"
      ],
      "metadata": {
        "id": "WxeJTMNuHfPf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "hfQfgdUMG-c7"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)\n",
        "\n",
        "# print(X_test[500])\n",
        "# print(y_test[500])"
      ],
      "metadata": {
        "id": "D6KtuX_TVFMj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba3ffecf-139b-4e65-8b3e-dc07955cc667"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4000, 10, 2)\n",
            "(4000, 1)\n",
            "(1000, 10, 2)\n",
            "(1000, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "t6LIhRyTHoJa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sigmoid activation function"
      ],
      "metadata": {
        "id": "hIcwm6jwbbIi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(x):\n",
        "  return 1 / (1 + np.exp(-x))"
      ],
      "metadata": {
        "id": "HHdc-w4yXSQm"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Elmon Network**"
      ],
      "metadata": {
        "id": "GAteUBZzbqov"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "class ElmanNet(torch.nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(ElmanNet, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        \n",
        "        # Initialize the weight matrices and bias vectors\n",
        "        self.weight_ih = torch.randn(input_size, hidden_size)\n",
        "        self.weight_hh = torch.randn(hidden_size, hidden_size)\n",
        "        self.bias = torch.zeros(1, hidden_size)\n",
        "        \n",
        "        # Initialize the linear layer\n",
        "        self.linear = torch.nn.Linear(hidden_size, output_size)\n",
        "        \n",
        "    def forward(self, inputs):\n",
        "        batch_size, seq_length, input_size = inputs.shape\n",
        "        inputs = inputs.transpose(0, 1)  # transpose to (seq_length, batch_size, input_size)\n",
        "        \n",
        "        # Initialize the hidden state\n",
        "        self.hidden = torch.zeros(batch_size, self.hidden_size)\n",
        "\n",
        "        # Loop through the sequence\n",
        "        for i in range(seq_length):\n",
        "            # Compute the hidden state\n",
        "            self.hidden = torch.tanh(torch.mm(inputs[i], self.weight_ih) + torch.mm(self.hidden, self.weight_hh) + self.bias)\n",
        "\n",
        "        # Compute the output\n",
        "        output = self.linear(self.hidden)\n",
        "\n",
        "        return output\n"
      ],
      "metadata": {
        "id": "PJPqKh4bbvr2"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initializing the Elman Network\n",
        "input_size = 2 #as each input sequence has depth = 2\n",
        "hidden_size = 128\n",
        "output_size = 1 #as we are predicting a single binary output value at each time step.\n",
        "model = ElmanNet(input_size, hidden_size, output_size)\n",
        "\n",
        "# Define the loss function and optimizer\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.005)"
      ],
      "metadata": {
        "id": "xqRJexuubvr4"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training the Elman Network"
      ],
      "metadata": {
        "id": "5tcmqQT0bvr5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = torch.from_numpy(X_train).float()\n",
        "train_labels = torch.from_numpy(y_train).float()\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 100\n",
        "batch_size = 128\n",
        "elman_losses = []\n",
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0.0\n",
        "    for i in range(0, len(train_data), batch_size):\n",
        "        # Get the current batch\n",
        "        inputs = train_data[i:i+batch_size]\n",
        "        labels = train_labels[i:i+batch_size]\n",
        "\n",
        "        # Clear the gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(inputs)\n",
        "        # print('outputs: ',outputs.shape)\n",
        "        # print('labels: ', labels.shape)\n",
        "\n",
        "        # Computing the loss\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}, Elman Training Loss: {running_loss}\")\n",
        "    elman_losses.append(running_loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e82f8461-4a1b-49f4-fdcc-4e7c010d259b",
        "id": "TsduTY3Kbvr5"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Elman Training Loss: 18.289664685726166\n",
            "Epoch 2, Elman Training Loss: 10.000224620103836\n",
            "Epoch 3, Elman Training Loss: 8.340704053640366\n",
            "Epoch 4, Elman Training Loss: 7.499967321753502\n",
            "Epoch 5, Elman Training Loss: 6.89403510093689\n",
            "Epoch 6, Elman Training Loss: 6.422660201787949\n",
            "Epoch 7, Elman Training Loss: 6.057969897985458\n",
            "Epoch 8, Elman Training Loss: 5.782413840293884\n",
            "Epoch 9, Elman Training Loss: 5.580442652106285\n",
            "Epoch 10, Elman Training Loss: 5.437134400010109\n",
            "Epoch 11, Elman Training Loss: 5.338877782225609\n",
            "Epoch 12, Elman Training Loss: 5.274006247520447\n",
            "Epoch 13, Elman Training Loss: 5.23303547501564\n",
            "Epoch 14, Elman Training Loss: 5.208604604005814\n",
            "Epoch 15, Elman Training Loss: 5.1952332109212875\n",
            "Epoch 16, Elman Training Loss: 5.188993394374847\n",
            "Epoch 17, Elman Training Loss: 5.18717060983181\n",
            "Epoch 18, Elman Training Loss: 5.187952667474747\n",
            "Epoch 19, Elman Training Loss: 5.190170854330063\n",
            "Epoch 20, Elman Training Loss: 5.193098857998848\n",
            "Epoch 21, Elman Training Loss: 5.196302369236946\n",
            "Epoch 22, Elman Training Loss: 5.199534192681313\n",
            "Epoch 23, Elman Training Loss: 5.202662333846092\n",
            "Epoch 24, Elman Training Loss: 5.205623686313629\n",
            "Epoch 25, Elman Training Loss: 5.208393901586533\n",
            "Epoch 26, Elman Training Loss: 5.210970059037209\n",
            "Epoch 27, Elman Training Loss: 5.213359907269478\n",
            "Epoch 28, Elman Training Loss: 5.215575575828552\n",
            "Epoch 29, Elman Training Loss: 5.21763114631176\n",
            "Epoch 30, Elman Training Loss: 5.219540491700172\n",
            "Epoch 31, Elman Training Loss: 5.221316277980804\n",
            "Epoch 32, Elman Training Loss: 5.222970426082611\n",
            "Epoch 33, Elman Training Loss: 5.22451351583004\n",
            "Epoch 34, Elman Training Loss: 5.225955098867416\n",
            "Epoch 35, Elman Training Loss: 5.2273033410310745\n",
            "Epoch 36, Elman Training Loss: 5.228566095232964\n",
            "Epoch 37, Elman Training Loss: 5.2297500520944595\n",
            "Epoch 38, Elman Training Loss: 5.230861306190491\n",
            "Epoch 39, Elman Training Loss: 5.231905400753021\n",
            "Epoch 40, Elman Training Loss: 5.232887372374535\n",
            "Epoch 41, Elman Training Loss: 5.2338118851184845\n",
            "Epoch 42, Elman Training Loss: 5.2346828281879425\n",
            "Epoch 43, Elman Training Loss: 5.235504239797592\n",
            "Epoch 44, Elman Training Loss: 5.2362793534994125\n",
            "Epoch 45, Elman Training Loss: 5.237011536955833\n",
            "Epoch 46, Elman Training Loss: 5.237703487277031\n",
            "Epoch 47, Elman Training Loss: 5.238358125090599\n",
            "Epoch 48, Elman Training Loss: 5.238977625966072\n",
            "Epoch 49, Elman Training Loss: 5.239564433693886\n",
            "Epoch 50, Elman Training Loss: 5.240120753645897\n",
            "Epoch 51, Elman Training Loss: 5.240648031234741\n",
            "Epoch 52, Elman Training Loss: 5.241148397326469\n",
            "Epoch 53, Elman Training Loss: 5.241623565554619\n",
            "Epoch 54, Elman Training Loss: 5.242074832320213\n",
            "Epoch 55, Elman Training Loss: 5.24250365793705\n",
            "Epoch 56, Elman Training Loss: 5.242911413311958\n",
            "Epoch 57, Elman Training Loss: 5.243299350142479\n",
            "Epoch 58, Elman Training Loss: 5.243668586015701\n",
            "Epoch 59, Elman Training Loss: 5.244020059704781\n",
            "Epoch 60, Elman Training Loss: 5.244354769587517\n",
            "Epoch 61, Elman Training Loss: 5.244673922657967\n",
            "Epoch 62, Elman Training Loss: 5.244978025555611\n",
            "Epoch 63, Elman Training Loss: 5.245267897844315\n",
            "Epoch 64, Elman Training Loss: 5.245544418692589\n",
            "Epoch 65, Elman Training Loss: 5.245808467268944\n",
            "Epoch 66, Elman Training Loss: 5.246060431003571\n",
            "Epoch 67, Elman Training Loss: 5.246301040053368\n",
            "Epoch 68, Elman Training Loss: 5.246530637145042\n",
            "Epoch 69, Elman Training Loss: 5.24674990773201\n",
            "Epoch 70, Elman Training Loss: 5.246959716081619\n",
            "Epoch 71, Elman Training Loss: 5.247160151600838\n",
            "Epoch 72, Elman Training Loss: 5.247351691126823\n",
            "Epoch 73, Elman Training Loss: 5.24753475189209\n",
            "Epoch 74, Elman Training Loss: 5.247709959745407\n",
            "Epoch 75, Elman Training Loss: 5.247877582907677\n",
            "Epoch 76, Elman Training Loss: 5.248037859797478\n",
            "Epoch 77, Elman Training Loss: 5.248191311955452\n",
            "Epoch 78, Elman Training Loss: 5.248338058590889\n",
            "Epoch 79, Elman Training Loss: 5.248478636145592\n",
            "Epoch 80, Elman Training Loss: 5.248613148927689\n",
            "Epoch 81, Elman Training Loss: 5.248741939663887\n",
            "Epoch 82, Elman Training Loss: 5.248865365982056\n",
            "Epoch 83, Elman Training Loss: 5.2489834278821945\n",
            "Epoch 84, Elman Training Loss: 5.249096587300301\n",
            "Epoch 85, Elman Training Loss: 5.249205112457275\n",
            "Epoch 86, Elman Training Loss: 5.249308943748474\n",
            "Epoch 87, Elman Training Loss: 5.249408468604088\n",
            "Epoch 88, Elman Training Loss: 5.24950385093689\n",
            "Epoch 89, Elman Training Loss: 5.249595209956169\n",
            "Epoch 90, Elman Training Loss: 5.249682813882828\n",
            "Epoch 91, Elman Training Loss: 5.249766767024994\n",
            "Epoch 92, Elman Training Loss: 5.249847203493118\n",
            "Epoch 93, Elman Training Loss: 5.249924287199974\n",
            "Epoch 94, Elman Training Loss: 5.249998226761818\n",
            "Epoch 95, Elman Training Loss: 5.250069215893745\n",
            "Epoch 96, Elman Training Loss: 5.250137001276016\n",
            "Epoch 97, Elman Training Loss: 5.250202178955078\n",
            "Epoch 98, Elman Training Loss: 5.250264823436737\n",
            "Epoch 99, Elman Training Loss: 5.250324681401253\n",
            "Epoch 100, Elman Training Loss: 5.25038206577301\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Getting predictions as well as measuring performance of the Elman Network "
      ],
      "metadata": {
        "id": "iuXEfMQ1bvr7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Will use the updated Elman Network \n",
        "\n",
        "X_test_tensor = torch.from_numpy(X_test).float()\n",
        "y_test_tensor = torch.from_numpy(y_test)\n",
        "batch_size = 128\n",
        "\n",
        "# Evaluating the model on test set (1000 datapoints)\n",
        "with torch.no_grad():  #disabling gradient calculation (as inferencing)\n",
        "    \n",
        "    # Split the data into batches of size batch_size\n",
        "    num_batches = len(X_test_tensor) // batch_size\n",
        "    test_data_batches = torch.split(X_test_tensor[:num_batches*batch_size], batch_size)\n",
        "    test_label_batches = torch.split(y_test_tensor[:num_batches*batch_size], batch_size)\n",
        "    \n",
        "\n",
        "    test_loss = 0.0\n",
        "    num_batches = 0\n",
        "\n",
        "    # Making predictions for each batch\n",
        "    for test_data, test_labels in zip(test_data_batches, test_label_batches):\n",
        "        \n",
        "        # Pass the test data through the Elman Net model, updated by training \n",
        "        outputs = model(test_data)\n",
        "\n",
        "        # Computing the MSE between predicted outputs and Ground truth labels\n",
        "        loss = nn.MSELoss()(outputs, test_labels)\n",
        "        \n",
        "        # Accumulating the loss\n",
        "        test_loss += loss.item()\n",
        "        num_batches += 1\n",
        "\n",
        "\n",
        "# Computing the average test loss over all batches\n",
        "test_loss /= num_batches\n",
        "\n",
        "print(\"Test Loss for Elman Network: {:.6f}\".format(test_loss))\n",
        "elman_mse = test_loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06a772a6-da33-43e2-a129-f2c07fcef146",
        "id": "nNlV2CEfbvr7"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss for Elman Network: 0.177413\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cYBtFP9VxBZc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **LSTM**"
      ],
      "metadata": {
        "id": "bXmm7hqtRhsX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTM(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(LSTM, self).__init__()\n",
        "\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "\n",
        "        # Initialize the weight matrices\n",
        "        self.weight_ih = nn.Parameter(torch.Tensor(input_size, 4 * hidden_size))\n",
        "        self.weight_hh = nn.Parameter(torch.Tensor(hidden_size, 4 * hidden_size))\n",
        "        self.bias = nn.Parameter(torch.Tensor(4 * hidden_size))\n",
        "\n",
        "        # Initialize the output layer\n",
        "        self.linear = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "        # Initialize the hidden state and cell state\n",
        "        self.hidden = None\n",
        "        self.cell_state = None\n",
        "\n",
        "        # Initialize the weights and biases\n",
        "        self.init_weights()\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        # seq_length, batch_size, input_size = inputs.shape\n",
        "        batch_size, seq_length, input_size = inputs.shape\n",
        "        inputs = inputs.transpose(0, 1)  # transpose to (seq_length, batch_size, input_size)\n",
        "\n",
        "        # print(inputs.shape)\n",
        "        # print(inputs[0].shape)\n",
        "\n",
        "        # Initialize the hidden state and cell state\n",
        "        self.hidden = torch.zeros(batch_size, self.hidden_size)\n",
        "        \n",
        "        self.cell_state = torch.zeros(batch_size, self.hidden_size)\n",
        "      \n",
        "\n",
        "        # Loop through the sequence\n",
        "        for i in range(seq_length):\n",
        "            # Compute the input gate, forget gate, output gate, and candidate gate\n",
        "            \n",
        "            gates = torch.mm(inputs[i], self.weight_ih) + torch.mm(self.hidden, self.weight_hh) + self.bias\n",
        "            \n",
        "            input_gate, forget_gate, output_gate, candidate_gate = gates.chunk(4, 1)\n",
        "\n",
        "            # Apply the sigmoid activation function\n",
        "            input_gate = torch.sigmoid(input_gate)\n",
        "            forget_gate = torch.sigmoid(forget_gate)\n",
        "            output_gate = torch.sigmoid(output_gate)\n",
        "\n",
        "            # Apply the tanh activation function\n",
        "            candidate_gate = torch.tanh(candidate_gate)\n",
        "\n",
        "            # Compute the new cell state and hidden state\n",
        "            self.cell_state = forget_gate * self.cell_state + input_gate * candidate_gate\n",
        "            self.hidden = output_gate * torch.tanh(self.cell_state)\n",
        "\n",
        "        # Compute the output\n",
        "        output = self.linear(self.hidden)\n",
        "\n",
        "        return output\n",
        "\n",
        "    def init_weights(self):\n",
        "        # Initialize the weights with a normal distribution\n",
        "        nn.init.normal_(self.weight_ih, 0.0, 0.02)\n",
        "        nn.init.normal_(self.weight_hh, 0.0, 0.02)\n",
        "        nn.init.normal_(self.bias, 0.0, 0.02)\n",
        "        nn.init.normal_(self.linear.weight, 0.0, 0.02)\n",
        "        nn.init.normal_(self.linear.bias, 0.0, 0.02)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "1YtdHsjhV_BH"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initializing the LSTM network\n",
        "input_size = 2\n",
        "hidden_size = 128\n",
        "output_size = 1\n",
        "model = LSTM(input_size, hidden_size, output_size)\n",
        "\n",
        "# Define the loss function and optimizer\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.005)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "en3pzLbYvI0z"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training the LSTM"
      ],
      "metadata": {
        "id": "q6lrP2mHvjfD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = torch.from_numpy(X_train).float()\n",
        "train_labels = torch.from_numpy(y_train).float()\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 100\n",
        "batch_size = 128\n",
        "lstm_losses = []\n",
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0.0\n",
        "    for i in range(0, len(train_data), batch_size):\n",
        "        # Get the current batch\n",
        "        inputs = train_data[i:i+batch_size]\n",
        "        labels = train_labels[i:i+batch_size]\n",
        "\n",
        "        # Clear the gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(inputs)\n",
        "        # print('outputs: ',outputs.shape)\n",
        "        # print('labels: ', labels.shape)\n",
        "\n",
        "        # Computing the loss\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}, LSTM Training Loss: {running_loss}\")\n",
        "    lstm_losses.append(running_loss)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xt1Jt_LjviJn",
        "outputId": "622fe713-4224-4975-e466-5f3a84d60b17"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, LSTM Training Loss: 18.73641885817051\n",
            "Epoch 2, LSTM Training Loss: 5.34566105902195\n",
            "Epoch 3, LSTM Training Loss: 5.057914853096008\n",
            "Epoch 4, LSTM Training Loss: 5.0136245265603065\n",
            "Epoch 5, LSTM Training Loss: 4.90203058719635\n",
            "Epoch 6, LSTM Training Loss: 4.717830985784531\n",
            "Epoch 7, LSTM Training Loss: 4.365478374063969\n",
            "Epoch 8, LSTM Training Loss: 4.217089854180813\n",
            "Epoch 9, LSTM Training Loss: 4.1334880366921425\n",
            "Epoch 10, LSTM Training Loss: 4.026603251695633\n",
            "Epoch 11, LSTM Training Loss: 3.7626515552401543\n",
            "Epoch 12, LSTM Training Loss: 2.800171732902527\n",
            "Epoch 13, LSTM Training Loss: 1.053887820802629\n",
            "Epoch 14, LSTM Training Loss: 0.6188005786389112\n",
            "Epoch 15, LSTM Training Loss: 0.42204575799405575\n",
            "Epoch 16, LSTM Training Loss: 0.31988499453291297\n",
            "Epoch 17, LSTM Training Loss: 0.2543841013684869\n",
            "Epoch 18, LSTM Training Loss: 0.2162221116013825\n",
            "Epoch 19, LSTM Training Loss: 0.17265726439654827\n",
            "Epoch 20, LSTM Training Loss: 0.12480153236538172\n",
            "Epoch 21, LSTM Training Loss: 0.10756745166145265\n",
            "Epoch 22, LSTM Training Loss: 0.09556223184335977\n",
            "Epoch 23, LSTM Training Loss: 0.08257446880452335\n",
            "Epoch 24, LSTM Training Loss: 0.07056791975628585\n",
            "Epoch 25, LSTM Training Loss: 0.05983175500296056\n",
            "Epoch 26, LSTM Training Loss: 0.048365975730121136\n",
            "Epoch 27, LSTM Training Loss: 0.03606404032325372\n",
            "Epoch 28, LSTM Training Loss: 0.030993273598141968\n",
            "Epoch 29, LSTM Training Loss: 0.030807105475105345\n",
            "Epoch 30, LSTM Training Loss: 0.02830720378551632\n",
            "Epoch 31, LSTM Training Loss: 0.023052881442708895\n",
            "Epoch 32, LSTM Training Loss: 0.018348720826907083\n",
            "Epoch 33, LSTM Training Loss: 0.017811928177252412\n",
            "Epoch 34, LSTM Training Loss: 0.014107897906797007\n",
            "Epoch 35, LSTM Training Loss: 0.012697836587904021\n",
            "Epoch 36, LSTM Training Loss: 0.012385183159494773\n",
            "Epoch 37, LSTM Training Loss: 0.011732920975191519\n",
            "Epoch 38, LSTM Training Loss: 0.012449961301172152\n",
            "Epoch 39, LSTM Training Loss: 0.01169578725239262\n",
            "Epoch 40, LSTM Training Loss: 0.011057925250497647\n",
            "Epoch 41, LSTM Training Loss: 0.01226982411753852\n",
            "Epoch 42, LSTM Training Loss: 0.014535698865074664\n",
            "Epoch 43, LSTM Training Loss: 0.01303389048553072\n",
            "Epoch 44, LSTM Training Loss: 0.01676734202192165\n",
            "Epoch 45, LSTM Training Loss: 0.022245855085202493\n",
            "Epoch 46, LSTM Training Loss: 0.018821485922671854\n",
            "Epoch 47, LSTM Training Loss: 0.012832426466047764\n",
            "Epoch 48, LSTM Training Loss: 0.008920344494981691\n",
            "Epoch 49, LSTM Training Loss: 0.010478666183189489\n",
            "Epoch 50, LSTM Training Loss: 0.01734931235841941\n",
            "Epoch 51, LSTM Training Loss: 0.011683016302413307\n",
            "Epoch 52, LSTM Training Loss: 0.012840416500694118\n",
            "Epoch 53, LSTM Training Loss: 0.016372881858842447\n",
            "Epoch 54, LSTM Training Loss: 0.011284540873020887\n",
            "Epoch 55, LSTM Training Loss: 0.013295045573613606\n",
            "Epoch 56, LSTM Training Loss: 0.013186656913603656\n",
            "Epoch 57, LSTM Training Loss: 0.009628513755160384\n",
            "Epoch 58, LSTM Training Loss: 0.012265081371879205\n",
            "Epoch 59, LSTM Training Loss: 0.008461301833449397\n",
            "Epoch 60, LSTM Training Loss: 0.03251454756536987\n",
            "Epoch 61, LSTM Training Loss: 0.03713234209863003\n",
            "Epoch 62, LSTM Training Loss: 0.01693648172658868\n",
            "Epoch 63, LSTM Training Loss: 0.007944029588543344\n",
            "Epoch 64, LSTM Training Loss: 0.007166632800363004\n",
            "Epoch 65, LSTM Training Loss: 0.007717540967860259\n",
            "Epoch 66, LSTM Training Loss: 0.008573132246965542\n",
            "Epoch 67, LSTM Training Loss: 0.016658448235830292\n",
            "Epoch 68, LSTM Training Loss: 0.011444938267231919\n",
            "Epoch 69, LSTM Training Loss: 0.01074570508353645\n",
            "Epoch 70, LSTM Training Loss: 0.014083030866459012\n",
            "Epoch 71, LSTM Training Loss: 0.012142896288423799\n",
            "Epoch 72, LSTM Training Loss: 0.010062268382171169\n",
            "Epoch 73, LSTM Training Loss: 0.012669049741816707\n",
            "Epoch 74, LSTM Training Loss: 0.015030246882815845\n",
            "Epoch 75, LSTM Training Loss: 0.00925777178053977\n",
            "Epoch 76, LSTM Training Loss: 0.009971363193471916\n",
            "Epoch 77, LSTM Training Loss: 0.014957998981117271\n",
            "Epoch 78, LSTM Training Loss: 0.013415220302704256\n",
            "Epoch 79, LSTM Training Loss: 0.010705063243221957\n",
            "Epoch 80, LSTM Training Loss: 0.013549657029216178\n",
            "Epoch 81, LSTM Training Loss: 0.01491492990317056\n",
            "Epoch 82, LSTM Training Loss: 0.008888612748705782\n",
            "Epoch 83, LSTM Training Loss: 0.008454009621345904\n",
            "Epoch 84, LSTM Training Loss: 0.012253315377165563\n",
            "Epoch 85, LSTM Training Loss: 0.013274587210617028\n",
            "Epoch 86, LSTM Training Loss: 0.007225201814435422\n",
            "Epoch 87, LSTM Training Loss: 0.0063856481574475765\n",
            "Epoch 88, LSTM Training Loss: 0.013363351215957664\n",
            "Epoch 89, LSTM Training Loss: 0.0042187240469502285\n",
            "Epoch 90, LSTM Training Loss: 0.016195932003029156\n",
            "Epoch 91, LSTM Training Loss: 0.013622434962599073\n",
            "Epoch 92, LSTM Training Loss: 0.003816548705799505\n",
            "Epoch 93, LSTM Training Loss: 0.01535927712393459\n",
            "Epoch 94, LSTM Training Loss: 0.025282433387474157\n",
            "Epoch 95, LSTM Training Loss: 0.009377169437357225\n",
            "Epoch 96, LSTM Training Loss: 0.015838742299820296\n",
            "Epoch 97, LSTM Training Loss: 0.018251506458909716\n",
            "Epoch 98, LSTM Training Loss: 0.014717730155098252\n",
            "Epoch 99, LSTM Training Loss: 0.004336060039349832\n",
            "Epoch 100, LSTM Training Loss: 0.009617061252356507\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Getting predictions as well as measuring performance of the LSTM Model"
      ],
      "metadata": {
        "id": "RmTOxevJ3J2s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Will use the updated LSTM model \n",
        "\n",
        "X_test_tensor = torch.from_numpy(X_test).float()\n",
        "y_test_tensor = torch.from_numpy(y_test)\n",
        "batch_size = 128\n",
        "\n",
        "# Evaluating the model on test set (1000 datapoints)\n",
        "with torch.no_grad():  #disabling gradient calculation (as inferencing)\n",
        "    \n",
        "    # Split the data into batches of size batch_size\n",
        "    num_batches = len(X_test_tensor) // batch_size\n",
        "    test_data_batches = torch.split(X_test_tensor[:num_batches*batch_size], batch_size)\n",
        "    test_label_batches = torch.split(y_test_tensor[:num_batches*batch_size], batch_size)\n",
        "    \n",
        "\n",
        "    test_loss = 0.0\n",
        "    num_batches = 0\n",
        "\n",
        "    # Making predictions for each batch\n",
        "    for test_data, test_labels in zip(test_data_batches, test_label_batches):\n",
        "        \n",
        "        # Pass the test data through the LSTM model, updated by training \n",
        "        outputs = model(test_data)\n",
        "\n",
        "        # Computing the MSE between predicted outputs and Ground truth labels\n",
        "        loss = nn.MSELoss()(outputs, test_labels)\n",
        "        \n",
        "        # Accumulating the loss\n",
        "        test_loss += loss.item()\n",
        "        num_batches += 1\n",
        "\n",
        "\n",
        "# Computing the average test loss over all batches\n",
        "test_loss /= num_batches\n",
        "\n",
        "print(\"Test Loss for LSTM: {:.6f}\".format(test_loss))\n",
        "lstm_mse = test_loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Blrno7ef3DgK",
        "outputId": "a97f8929-4217-4e90-83f6-1011832cd670"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss for LSTM: 0.000240\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CWLECAugvTjJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GRU**"
      ],
      "metadata": {
        "id": "rY7C9qqW_fG5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GRU(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(GRU, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        \n",
        "        # Initialize the weight matrices and biases\n",
        "        self.weight_ir = nn.Parameter(torch.Tensor(input_size, hidden_size))\n",
        "        self.weight_hr = nn.Parameter(torch.Tensor(hidden_size, hidden_size))\n",
        "        self.bias_r = nn.Parameter(torch.Tensor(hidden_size))\n",
        "        self.weight_iz = nn.Parameter(torch.Tensor(input_size, hidden_size))\n",
        "        self.weight_hz = nn.Parameter(torch.Tensor(hidden_size, hidden_size))\n",
        "        self.bias_z = nn.Parameter(torch.Tensor(hidden_size))\n",
        "        self.weight_in = nn.Parameter(torch.Tensor(input_size, hidden_size))\n",
        "        self.weight_hn = nn.Parameter(torch.Tensor(hidden_size, hidden_size))\n",
        "        self.bias_n = nn.Parameter(torch.Tensor(hidden_size))\n",
        "        self.linear = nn.Linear(hidden_size, output_size)\n",
        "        \n",
        "        # Initialize the parameters\n",
        "        self.init_parameters()\n",
        "        \n",
        "    def init_parameters(self):\n",
        "        # Initialize the weight matrices and biases\n",
        "        nn.init.xavier_uniform_(self.weight_ir)\n",
        "        nn.init.xavier_uniform_(self.weight_hr)\n",
        "        nn.init.zeros_(self.bias_r)\n",
        "        nn.init.xavier_uniform_(self.weight_iz)\n",
        "        nn.init.xavier_uniform_(self.weight_hz)\n",
        "        nn.init.zeros_(self.bias_z)\n",
        "        nn.init.xavier_uniform_(self.weight_in)\n",
        "        nn.init.xavier_uniform_(self.weight_hn)\n",
        "        nn.init.zeros_(self.bias_n)\n",
        "        \n",
        "    def forward(self, inputs):\n",
        "        batch_size, seq_length, input_size = inputs.shape\n",
        "        inputs = inputs.transpose(0, 1)  # transpose to (seq_length, batch_size, input_size)\n",
        "        # print(inputs.shape)\n",
        "        \n",
        "        # Initialize the hidden state\n",
        "        hidden = torch.zeros(batch_size, self.hidden_size)\n",
        "        \n",
        "        # Loop through the sequence\n",
        "        for i in range(seq_length):\n",
        "            # Compute the reset gate\n",
        "            reset_gate = torch.sigmoid(torch.mm(inputs[i], self.weight_ir) + torch.mm(hidden, self.weight_hr) + self.bias_r)\n",
        "            \n",
        "            # Compute the update gate\n",
        "            update_gate = torch.sigmoid(torch.mm(inputs[i], self.weight_iz) + torch.mm(hidden, self.weight_hz) + self.bias_z)\n",
        "            \n",
        "            # Compute the new candidate activations\n",
        "            candidate_activations = torch.tanh(torch.mm(inputs[i], self.weight_in) + reset_gate * torch.mm(hidden, self.weight_hn) + self.bias_n)\n",
        "            \n",
        "            # Compute the new hidden state\n",
        "            hidden = (1 - update_gate) * hidden + update_gate * candidate_activations\n",
        "        \n",
        "        # Compute the output\n",
        "        output = self.linear(hidden)\n",
        "        \n",
        "        return output\n"
      ],
      "metadata": {
        "id": "fsy5t34h_eiT"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initializing the GRU network\n",
        "input_size = 2\n",
        "hidden_size = 128\n",
        "output_size = 1\n",
        "model = GRU(input_size, hidden_size, output_size)\n",
        "\n",
        "# Define the loss function and optimizer\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.005)"
      ],
      "metadata": {
        "id": "Q2Hg9xy6_eli"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training the GRU"
      ],
      "metadata": {
        "id": "yHYRuh13B_TD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = torch.from_numpy(X_train).float()\n",
        "train_labels = torch.from_numpy(y_train).float()\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 100\n",
        "batch_size = 128\n",
        "gru_losses = []\n",
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0.0\n",
        "    for i in range(0, len(train_data), batch_size):\n",
        "        # Get the current batch\n",
        "        inputs = train_data[i:i+batch_size]\n",
        "        labels = train_labels[i:i+batch_size]\n",
        "\n",
        "        # Clear the gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(inputs)\n",
        "        # print('outputs: ',outputs.shape)\n",
        "        # print('labels: ', labels.shape)\n",
        "\n",
        "        # Computing the loss\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}, GRU Training Loss: {running_loss}\")\n",
        "    gru_losses.append(running_loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2V90blWLB-YO",
        "outputId": "e7d8482b-3e21-4986-cdb3-e4a7f270f27b"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, GRU Training Loss: 8.389917127788067\n",
            "Epoch 2, GRU Training Loss: 4.382082901895046\n",
            "Epoch 3, GRU Training Loss: 3.71613273024559\n",
            "Epoch 4, GRU Training Loss: 2.0018900707364082\n",
            "Epoch 5, GRU Training Loss: 0.8639416396617889\n",
            "Epoch 6, GRU Training Loss: 0.49671305157244205\n",
            "Epoch 7, GRU Training Loss: 0.24093755893409252\n",
            "Epoch 8, GRU Training Loss: 0.12714167800731957\n",
            "Epoch 9, GRU Training Loss: 0.0831200018292293\n",
            "Epoch 10, GRU Training Loss: 0.05940751079469919\n",
            "Epoch 11, GRU Training Loss: 0.0448250753688626\n",
            "Epoch 12, GRU Training Loss: 0.03241402131970972\n",
            "Epoch 13, GRU Training Loss: 0.0211391870980151\n",
            "Epoch 14, GRU Training Loss: 0.015219732566038147\n",
            "Epoch 15, GRU Training Loss: 0.012099404659238644\n",
            "Epoch 16, GRU Training Loss: 0.010680001345463097\n",
            "Epoch 17, GRU Training Loss: 0.008155876654200256\n",
            "Epoch 18, GRU Training Loss: 0.007957476715091616\n",
            "Epoch 19, GRU Training Loss: 0.007077291505993344\n",
            "Epoch 20, GRU Training Loss: 0.005408468765381258\n",
            "Epoch 21, GRU Training Loss: 0.005180198299058247\n",
            "Epoch 22, GRU Training Loss: 0.005639060873363633\n",
            "Epoch 23, GRU Training Loss: 0.0066080922915716656\n",
            "Epoch 24, GRU Training Loss: 0.00777702758932719\n",
            "Epoch 25, GRU Training Loss: 0.007749440148472786\n",
            "Epoch 26, GRU Training Loss: 0.007084714088705368\n",
            "Epoch 27, GRU Training Loss: 0.006327183822577354\n",
            "Epoch 28, GRU Training Loss: 0.005244487467280123\n",
            "Epoch 29, GRU Training Loss: 0.003622283777076518\n",
            "Epoch 30, GRU Training Loss: 0.0046766678569838405\n",
            "Epoch 31, GRU Training Loss: 0.006695671836496331\n",
            "Epoch 32, GRU Training Loss: 0.007901588676759275\n",
            "Epoch 33, GRU Training Loss: 0.010004596988437697\n",
            "Epoch 34, GRU Training Loss: 0.004164996829786105\n",
            "Epoch 35, GRU Training Loss: 0.0028961487878405023\n",
            "Epoch 36, GRU Training Loss: 0.0038777722875238396\n",
            "Epoch 37, GRU Training Loss: 0.002414425449387636\n",
            "Epoch 38, GRU Training Loss: 0.0028757638574461453\n",
            "Epoch 39, GRU Training Loss: 0.004066130528372014\n",
            "Epoch 40, GRU Training Loss: 0.00731520590125001\n",
            "Epoch 41, GRU Training Loss: 0.009346644383185776\n",
            "Epoch 42, GRU Training Loss: 0.008424435272900155\n",
            "Epoch 43, GRU Training Loss: 0.003398879707674496\n",
            "Epoch 44, GRU Training Loss: 0.004211773022689158\n",
            "Epoch 45, GRU Training Loss: 0.0032742365801823325\n",
            "Epoch 46, GRU Training Loss: 0.005540096384720528\n",
            "Epoch 47, GRU Training Loss: 0.004758203940582462\n",
            "Epoch 48, GRU Training Loss: 0.005879824337171158\n",
            "Epoch 49, GRU Training Loss: 0.0047699481328891125\n",
            "Epoch 50, GRU Training Loss: 0.0040919499115261715\n",
            "Epoch 51, GRU Training Loss: 0.004012817782495404\n",
            "Epoch 52, GRU Training Loss: 0.003978652732257615\n",
            "Epoch 53, GRU Training Loss: 0.0039921121915540425\n",
            "Epoch 54, GRU Training Loss: 0.00421650491807668\n",
            "Epoch 55, GRU Training Loss: 0.004311126300308388\n",
            "Epoch 56, GRU Training Loss: 0.004468788058147766\n",
            "Epoch 57, GRU Training Loss: 0.004979058054232155\n",
            "Epoch 58, GRU Training Loss: 0.005110740237796563\n",
            "Epoch 59, GRU Training Loss: 0.00508884863302228\n",
            "Epoch 60, GRU Training Loss: 0.006944689313968411\n",
            "Epoch 61, GRU Training Loss: 0.009070160835108254\n",
            "Epoch 62, GRU Training Loss: 0.005994031256705057\n",
            "Epoch 63, GRU Training Loss: 0.0020476656845858088\n",
            "Epoch 64, GRU Training Loss: 0.0013005510245420737\n",
            "Epoch 65, GRU Training Loss: 0.001917907971801469\n",
            "Epoch 66, GRU Training Loss: 0.003249800915000378\n",
            "Epoch 67, GRU Training Loss: 0.005866302009962965\n",
            "Epoch 68, GRU Training Loss: 0.005067364496426308\n",
            "Epoch 69, GRU Training Loss: 0.007574812818347709\n",
            "Epoch 70, GRU Training Loss: 0.008044553003855981\n",
            "Epoch 71, GRU Training Loss: 0.0018132462519133696\n",
            "Epoch 72, GRU Training Loss: 0.0013614897870866116\n",
            "Epoch 73, GRU Training Loss: 0.0016885711593204178\n",
            "Epoch 74, GRU Training Loss: 0.002424355308903614\n",
            "Epoch 75, GRU Training Loss: 0.0050967630741070025\n",
            "Epoch 76, GRU Training Loss: 0.002486659335772856\n",
            "Epoch 77, GRU Training Loss: 0.002831979378242977\n",
            "Epoch 78, GRU Training Loss: 0.028645408274314832\n",
            "Epoch 79, GRU Training Loss: 0.012499849399318919\n",
            "Epoch 80, GRU Training Loss: 0.003648310583230341\n",
            "Epoch 81, GRU Training Loss: 0.0018843047346308595\n",
            "Epoch 82, GRU Training Loss: 0.0024587361767771654\n",
            "Epoch 83, GRU Training Loss: 0.0025389563543285476\n",
            "Epoch 84, GRU Training Loss: 0.0019097701679129386\n",
            "Epoch 85, GRU Training Loss: 0.0012898497516289353\n",
            "Epoch 86, GRU Training Loss: 0.0009976608898796258\n",
            "Epoch 87, GRU Training Loss: 0.0008814348111627623\n",
            "Epoch 88, GRU Training Loss: 0.0008207072414734284\n",
            "Epoch 89, GRU Training Loss: 0.0008373112068511546\n",
            "Epoch 90, GRU Training Loss: 0.0010603657647152431\n",
            "Epoch 91, GRU Training Loss: 0.006297370084212162\n",
            "Epoch 92, GRU Training Loss: 0.002064059142867336\n",
            "Epoch 93, GRU Training Loss: 0.010058879906864604\n",
            "Epoch 94, GRU Training Loss: 0.006580201761607896\n",
            "Epoch 95, GRU Training Loss: 0.0065524213587195845\n",
            "Epoch 96, GRU Training Loss: 0.002126453906384995\n",
            "Epoch 97, GRU Training Loss: 0.002452801931212889\n",
            "Epoch 98, GRU Training Loss: 0.001166124679002678\n",
            "Epoch 99, GRU Training Loss: 0.0011942026121687377\n",
            "Epoch 100, GRU Training Loss: 0.0015160160492087016\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Getting predictions as well as measuring performance of the GRU Model"
      ],
      "metadata": {
        "id": "58PTU48lEggN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Will use the updated GRU model \n",
        "\n",
        "X_test_tensor = torch.from_numpy(X_test).float()\n",
        "y_test_tensor = torch.from_numpy(y_test)\n",
        "batch_size = 128\n",
        "\n",
        "# Evaluating the model on test set (1000 datapoints)\n",
        "with torch.no_grad():  #disabling gradient calculation (as inferencing)\n",
        "    \n",
        "    # Split the data into batches of size batch_size\n",
        "    num_batches = len(X_test_tensor) // batch_size\n",
        "    test_data_batches = torch.split(X_test_tensor[:num_batches*batch_size], batch_size)\n",
        "    test_label_batches = torch.split(y_test_tensor[:num_batches*batch_size], batch_size)\n",
        "    \n",
        "\n",
        "    test_loss = 0.0\n",
        "    num_batches = 0\n",
        "\n",
        "    # Making predictions for each batch\n",
        "    for test_data, test_labels in zip(test_data_batches, test_label_batches):\n",
        "        \n",
        "        # Pass the test data through the GRU model, updated by training \n",
        "        outputs = model(test_data)\n",
        "\n",
        "        # Computing the MSE between predicted outputs and Ground truth labels\n",
        "        loss = nn.MSELoss()(outputs, test_labels)\n",
        "        \n",
        "        # Accumulating the loss\n",
        "        test_loss += loss.item()\n",
        "        num_batches += 1\n",
        "\n",
        "\n",
        "# Computing the average test loss over all batches\n",
        "test_loss /= num_batches\n",
        "\n",
        "print(\"Test Loss for GRU: {:.6f}\".format(test_loss))\n",
        "gru_mse = test_loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0PeOF5OTBkLl",
        "outputId": "9ec1d0f4-b70d-4af5-e8bc-b86998b3ab8d"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss for GRU: 0.000037\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Gy1FgbaDB0YU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Baseline**"
      ],
      "metadata": {
        "id": "I__8x7C_G1Xp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Baseline that always predicts the sum as 1\n",
        "def Baseline(X_test_tensor):\n",
        "  batch_size = test_data.shape[0]\n",
        "  output = torch.ones(batch_size,1)\n",
        "  return output\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "hwGDfeSjB0b1"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Getting predictions as well as measuring performance of the Baseline"
      ],
      "metadata": {
        "id": "GCUoo-pBPPwn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "X_test_tensor = torch.from_numpy(X_test).float()\n",
        "y_test_tensor = torch.from_numpy(y_test)\n",
        "batch_size = 128\n",
        "\n",
        "# Evaluating the Baseline on test set (1000 datapoints)\n",
        "with torch.no_grad():  #disabling gradient calculation (as inferencing)\n",
        "    \n",
        "    # Split the data into batches of size batch_size\n",
        "    num_batches = len(X_test_tensor) // batch_size\n",
        "    test_data_batches = torch.split(X_test_tensor[:num_batches*batch_size], batch_size)\n",
        "    test_label_batches = torch.split(y_test_tensor[:num_batches*batch_size], batch_size)\n",
        "    \n",
        "\n",
        "    test_loss = 0.0\n",
        "    num_batches = 0\n",
        "\n",
        "    # Making predictions for each batch\n",
        "    for test_data, test_labels in zip(test_data_batches, test_label_batches):\n",
        "        \n",
        "        # Pass the test data through the baseline\n",
        "        outputs = Baseline(test_data)\n",
        "\n",
        "        # Computing the MSE between predicted outputs and Ground truth labels\n",
        "        loss = nn.MSELoss()(outputs, test_labels)\n",
        "        \n",
        "        # Accumulating the loss\n",
        "        test_loss += loss.item()\n",
        "        num_batches += 1\n",
        "\n",
        "\n",
        "# Computing the average test loss over all batches\n",
        "test_loss /= num_batches\n",
        "\n",
        "print(\"Test Loss for Baseline: {:.6f}\".format(test_loss))\n",
        "base_mse = test_loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_WbOyx2eJj63",
        "outputId": "469275e4-298f-4fd8-85b6-2518570258cb"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss for Baseline: 0.173563\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QiRA3krxO6YL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Comparing the performance of all the models by plotting their learning curves and final performance** "
      ],
      "metadata": {
        "id": "MoJav3WkMfeC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Plotting learning curves (As Baseline model do not need learning, its curve is not present here)\n",
        "plt.plot(elman_losses, label='Elman')\n",
        "plt.plot(lstm_losses, label='LSTM')\n",
        "plt.plot(gru_losses, label='GRU')\n",
        "plt.legend()\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Training Loss (MSE)')\n",
        "plt.title('Learning Curves')\n",
        "plt.show()\n",
        "\n",
        "# Plotting final performance\n",
        "plt.bar(['Baseline', 'Elman', 'LSTM', 'GRU'], [base_mse, elman_mse, lstm_mse, gru_mse])\n",
        "plt.ylabel('MSE')\n",
        "plt.title('Final Performance (Test Loss)')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 907
        },
        "id": "HWKe9484MZom",
        "outputId": "141faaf7-5bf2-41f1-d928-36237c821864"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "y8bctLn0BkPc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}